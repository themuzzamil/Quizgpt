{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja_NhOFKpCV9",
        "outputId": "a60a49f5-38c2-426e-cc2e-61a705e2b3e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU pypdf\n",
        "!pip install -qU pypdf scikit-learn langchain_community\n",
        "!pip install --quiet langchain langchain-text-splitters langchain_google_genai\n",
        "!pip install --quiet langchain_chroma\n",
        "!pip install --quiet cohere\n",
        "!pip install --upgrade --quiet langchain\n",
        "!pip install --quiet PyPDF2\n",
        "\n",
        "!pip install -q cohere\n",
        "\n",
        "\n",
        "!pip install --quiet google-api-python-client google-auth-httplib2 google-auth-oauthlib PyPDF2 langgraph\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "import sqlite3\n",
        "from google.colab import files\n",
        "import PyPDF2\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.embeddings import CohereEmbeddings\n",
        "from langchain.schema import Document\n",
        "from uuid import uuid4\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langchain.schema import Document\n",
        "from pprint import pprint\n",
        "from typing import Any, List, TypedDict\n",
        "from IPython.display import display, Markdown\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langgraph.store.base import BaseStore\n"
      ],
      "metadata": {
        "id": "ECsLWXykpeId"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "llm = GoogleGenerativeAI(google_api_key=GEMINI_API_KEY, model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "Hd4EuJzEpo0t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from uuid import uuid4\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import CohereEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from IPython.display import Markdown\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langgraph.store.base import BaseStore\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from typing import List, Any, TypedDict\n",
        "from pprint import pprint\n",
        "from langgraph.graph import StateGraph, END,START\n",
        "from IPython.display import Image, display\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from typing import Literal\n",
        "\n",
        "import PyPDF2\n",
        "from google.colab import files\n",
        "\n",
        "# SQLite database setup\n",
        "db_path = \"uploaded_files_metadata.db\"\n",
        "\n",
        "# Function to initialize the database and create table if not exists\n",
        "def initialize_db():\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS uploaded_files (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            collection_name TEXT UNIQUE,\n",
        "            file_name TEXT\n",
        "        )\n",
        "    ''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Function to insert file metadata into SQLite\n",
        "def save_metadata(collection_name, file_name):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "        INSERT OR IGNORE INTO uploaded_files (collection_name, file_name)\n",
        "        VALUES (?, ?)\n",
        "    ''', (collection_name, file_name))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Function to load metadata from SQLite\n",
        "def load_metadata():\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('SELECT collection_name, file_name FROM uploaded_files')\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return {row[0]: row[1] for row in rows}\n",
        "\n",
        "# Load and split PDF content\n",
        "def load_pdf(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "# Process PDF to update vector store\n",
        "def process_pdf(file_name, collection_name):\n",
        "    pdf_content = load_pdf(file_name)\n",
        "    if pdf_content:\n",
        "        print(\"PDF content loaded successfully.\")\n",
        "\n",
        "        cohere_api_key = userdata.get(\"Embedding_API\")  # Replace with actual key\n",
        "        embedding_function = CohereEmbeddings(\n",
        "            model=\"embed-english-light-v2.0\",\n",
        "            cohere_api_key=cohere_api_key,\n",
        "            user_agent=\"LangChainCohere\"\n",
        "        )\n",
        "\n",
        "\n",
        "        vector_db = Chroma(\n",
        "            collection_name=collection_name,\n",
        "            embedding_function=embedding_function\n",
        "        )\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
        "        docs = [Document(page_content=pdf_content)]\n",
        "        chunks = text_splitter.split_documents(docs)\n",
        "\n",
        "        vector_db.add_texts([chunk.page_content for chunk in chunks])\n",
        "\n",
        "        print(f\"PDF data from {file_name} updated in vector_db.\")\n",
        "        save_metadata(collection_name, file_name)\n",
        "\n",
        "# Handle file selection or upload\n",
        "def handle_file_selection() -> str:\n",
        "    uploaded_files_metadata = load_metadata()\n",
        "    if uploaded_files_metadata:\n",
        "        print(\"Previously uploaded files:\")\n",
        "        for i, (collection, file_name) in enumerate(uploaded_files_metadata.items()):\n",
        "            print(f\"{i + 1}: {file_name} (Collection: {collection})\")\n",
        "        choice = input(\"Enter the number of the file to use or 'N' to upload a new one: \")\n",
        "\n",
        "        if choice.upper() == 'N':\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                uploaded_file_path = next(iter(uploaded))\n",
        "                print(f\"Uploaded file: {uploaded_file_path}\")\n",
        "\n",
        "                unique_collection_name = f\"pdf_chunks_{uuid4()}\"\n",
        "                process_pdf(uploaded_file_path, unique_collection_name)\n",
        "                return unique_collection_name\n",
        "        else:\n",
        "            chosen_index = int(choice) - 1\n",
        "            chosen_collection = list(uploaded_files_metadata.keys())[chosen_index]\n",
        "            print(f\"Using previously uploaded file: {uploaded_files_metadata[chosen_collection]}\")\n",
        "            return chosen_collection\n",
        "    else:\n",
        "        print(\"No files found in the vector DB. Please upload a new file.\")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            uploaded_file_path = next(iter(uploaded))\n",
        "            print(f\"Uploaded file: {uploaded_file_path}\")\n",
        "\n",
        "            unique_collection_name = f\"pdf_chunks_{uuid4()}\"\n",
        "            process_pdf(uploaded_file_path, unique_collection_name)\n",
        "            return unique_collection_name\n",
        "\n",
        "# Initialize the database\n",
        "initialize_db()\n",
        "\n",
        "# Get the collection name based on user input\n",
        "collection_name = handle_file_selection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "6cBRo_2upt03",
        "outputId": "5a486487-0cec-49d6-d5cf-0f34b880ce70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No files found in the vector DB. Please upload a new file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a2290df-6732-4c35-97de-209b60029313\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3a2290df-6732-4c35-97de-209b60029313\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving python-basics-sample-chapters (2).pdf to python-basics-sample-chapters (2).pdf\n",
            "Uploaded file: python-basics-sample-chapters (2).pdf\n",
            "PDF content loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-812755e16139>:79: LangChainDeprecationWarning: The class `CohereEmbeddings` was deprecated in LangChain 0.0.30 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-cohere package and should be used instead. To use it run `pip install -U :class:`~langchain-cohere` and import as `from :class:`~langchain_cohere import CohereEmbeddings``.\n",
            "  embedding_function = CohereEmbeddings(\n",
            "<ipython-input-4-812755e16139>:86: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vector_db = Chroma(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF data from python-basics-sample-chapters (2).pdf updated in vector_db.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "from pprint import pprint\n",
        "from typing_extensions import Any, List, TypedDict\n",
        "from IPython.display import display, Markdown\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "import json\n",
        "from langgraph.store.base import BaseStore\n",
        "\n",
        "class Question(TypedDict):\n",
        "    question: str\n",
        "    options: dict[str, str]\n",
        "    answer: str\n",
        "    user_response: str\n",
        "\n",
        "class StateDocument(TypedDict):\n",
        "    questions: List[Question]\n",
        "    total_questions: int\n",
        "    current_question: int\n",
        "    human_input: str\n",
        "    ai_output: str\n",
        "    human_input_2: str\n",
        "    chat: str\n",
        "    decision: str\n",
        "    score: int\n",
        "    reason : str\n",
        "\n",
        "\n",
        "from IPython.display import Markdown\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "config = {\"configurable\": {\"user_id\": \"1\"}}\n",
        "across_thread_memory = InMemoryStore()\n",
        "\n",
        "\n",
        "# Define a VectorDatabase class to interact with the Chroma database\n",
        "class VectorDatabase:\n",
        "    def __init__(self, chroma_db: Chroma):\n",
        "        self.chroma_db = chroma_db\n",
        "\n",
        "    def similarity_search(self, query: str, k: int) -> List[Any]:\n",
        "        \"\"\"Performs a similarity search using the Chroma database.\"\"\"\n",
        "        return self.chroma_db.similarity_search(query, k=k)\n",
        "\n",
        "def questions(state: StateDocument) -> StateDocument:\n",
        "    while True:\n",
        "\n",
        "      total_questions = __builtins__.input(\"How many questions do you want to generate (0 to 25): \")\n",
        "      try:\n",
        "        total_questions = int(total_questions)  # Convert to integer\n",
        "        if 0 < total_questions <= 25:\n",
        "          state[\"human_input\"] = total_questions\n",
        "          break  # Exit the loop if input is valid\n",
        "        else:\n",
        "          print(\"Invalid input. Please enter a number between 1 and 25.\")\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a valid number.\")\n",
        "        return state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clean_json_input(raw_input):\n",
        "    \"\"\"\n",
        "    Cleans the raw JSON input by removing enclosing backticks and the word 'json'.\n",
        "\n",
        "    Args:\n",
        "        raw_input (str): The raw JSON string with backticks and 'json'.\n",
        "\n",
        "    Returns:\n",
        "        dict: A Python dictionary representation of the cleaned JSON.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Remove backticks and 'json' keyword\n",
        "        cleaned_input = raw_input.strip(\"```\").replace(\"json\", \"\").strip()\n",
        "        cleaned_input = cleaned_input.replace(\"```\", \"\")\n",
        "        # print(cleaned_input)\n",
        "        # Parse the cleaned JSON string into a dictionary\n",
        "        return json.loads(cleaned_input)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        return {\"error\": f\"Invalid JSON format: {e}\"}\n",
        "\n",
        "    # Clean the input and print the result\n",
        "    cleaned_json = clean_json_input(raw_input)\n",
        "    return json.dumps(cleaned_json, indent=4)\n",
        "\n",
        "\n",
        "def parse_questions(ai_output):\n",
        "    \"\"\"\n",
        "    Parses multiple questions, options, answers, and user responses from AI output and stores them.\n",
        "\n",
        "    Args:\n",
        "        ai_output: The output from the language model, expected to be in JSON format as a list of questions.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries representing the questions in the desired format.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse the AI output into a Python object\n",
        "        if isinstance(ai_output, list):\n",
        "            # print(\"Ai out put is list\")\n",
        "            parsed_output = ai_output\n",
        "        else:\n",
        "            # print(\"Ai out put is Json\")\n",
        "            parsed_output = json.loads(ai_output)\n",
        "\n",
        "        # # Validate the structure\n",
        "        if not isinstance(parsed_output, list):\n",
        "            raise ValueError(\"AI output must be a list of questions.\")\n",
        "\n",
        "\n",
        "        # Process each question and store it\n",
        "        questions = []\n",
        "        for question_data in parsed_output:\n",
        "            question = question_data.get(\"question\")\n",
        "            options = question_data.get(\"options\")\n",
        "            answer = question_data.get(\"answer\")\n",
        "\n",
        "            # Validate required fields\n",
        "            if not question or not options or not answer:\n",
        "                raise ValueError(\"Each question must include 'question', 'options', and 'answer'.\")\n",
        "\n",
        "            if not isinstance(options, dict):\n",
        "                raise ValueError(\"Options must be a dictionary with keys (A, B, C, D).\")\n",
        "            structured_options = [\n",
        "              f\"{key}: {value}\" for key, value in options.items()]\n",
        "\n",
        "            # Add the question to the list\n",
        "            questions.append({\n",
        "                \"question\": question,\n",
        "                \"options\": structured_options,\n",
        "                \"answer\": answer,\n",
        "                \"user_response\": None  # Default value\n",
        "            })\n",
        "\n",
        "        return questions\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: AI output is not valid JSON.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def node_2(db: VectorDatabase, state: StateDocument) -> StateDocument:\n",
        "\n",
        "    no_of_questions = state[\"human_input\"]\n",
        "    state[\"total_questions\"] = int(no_of_questions)\n",
        "    # Format the prompt for quiz creation\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert quiz creator. Create {no_of_questions} quiz questions. Each question should have four multiple-choice options (A, B, C, D), and provide the correct answer.\n",
        "\n",
        "    Strictly adhere to the following format for each question:\n",
        "    [\n",
        "        {{\n",
        "            'question': '[Question Text]',\n",
        "            'options': {{\n",
        "                'A': '[Option A]',\n",
        "                'B': '[Option B]',\n",
        "                'C': '[Option C]',\n",
        "                'D': '[Option D]'\n",
        "            }},\n",
        "            'answer': '[Correct Option Letter]'  # Only use A, B, C, or D\n",
        "        }},\n",
        "        ...\n",
        "    ]\n",
        "\n",
        "    For example:\n",
        "    [\n",
        "        {{\n",
        "            'question': 'What is the capital of France?',\n",
        "            'options': {{\n",
        "                'A': 'Berlin',\n",
        "                'B': 'Madrid',\n",
        "                'C': 'Paris',\n",
        "                'D': 'Rome'\n",
        "            }},\n",
        "            'answer': 'C'\n",
        "        }}\n",
        "    ]\n",
        "\n",
        "    Do not deviate from this format. Do not hallucinate. Provide all questions in this exact structure.\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve context from the database\n",
        "    relevant_docs = db.chroma_db.get()\n",
        "    documents = [Document(page_content=text) for text in relevant_docs[\"documents\"]]\n",
        "    context = \" \".join([doc.page_content for doc in documents])\n",
        "\n",
        "    prompt_with_context = f\"{prompt}\\n\\nContext: {context}\"\n",
        "\n",
        "    # Call your LLM here (replace with actual LLM call)\n",
        "    result = llm.invoke(prompt_with_context)\n",
        "    state[\"questionset\"] = result\n",
        "    clean = clean_json_input(result)\n",
        "    parsed = parse_questions(clean)\n",
        "    state[\"questions\"] = parsed\n",
        "    # print(parsed)\n",
        "    # return state\n",
        "\n",
        "def node_3(db: VectorDatabase, state: StateDocument, config: RunnableConfig, store: BaseStore) -> StateDocument:\n",
        "    # Retrieve context related to recent PDF for chat input\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    namespace = (user_id)\n",
        "    existing_memory = store.get(namespace, \"user_memory\")\n",
        "\n",
        "    if existing_memory:\n",
        "        existing_memory_content = existing_memory.value.get('memory')\n",
        "    else:\n",
        "        existing_memory_content = \"No existing memory found.\"\n",
        "\n",
        "\n",
        "    # Check if existing_memory is a dictionary and has a 'memory' key.\n",
        "    # If not, assume it's the memory content and use it directly.\n",
        "\n",
        "\n",
        "    relevant_docs = db.similarity_search(state[\"human_input_2\"], k=2)\n",
        "    context = \" \".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "    # Construct the prompt with context\n",
        "    prompt = f\"\"\"\n",
        "    Provide information based on the context below.\n",
        "    Don't hallucinate or web search information.\n",
        "    If user greet you then interact with him greet him/her.\n",
        "    But when user ask any question then provide him with answer.\n",
        "    or prompt similar to it just to help out user.\n",
        "    Query input: \"{state['human_input_2']}\"\n",
        "    Context: {context}\n",
        "\n",
        "    You are a helpful assistant with memory that provides information about the user.\n",
        "    If you have memory for this user, use it to personalize your responses.\n",
        "    Here is the memory (it may be empty): {existing_memory_content}\n",
        "    User: {state[\"human_input_2\"]}\"\"\"\n",
        "\n",
        "    # Invoke the LLM with the prompt, no need to format again\n",
        "    state[\"chat\"] = llm.invoke(prompt)\n",
        "    store.put(namespace, \"user_memory\", {\"memory\": state[\"chat\"]})  # Use send_message and extract the text from the response\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "cohere_api_key = userdata.get(\"Embedding_API\")  # Replace with actual key\n",
        "embedding_function = CohereEmbeddings(\n",
        "    model=\"embed-english-light-v2.0\",\n",
        "    cohere_api_key=cohere_api_key,\n",
        "    user_agent=\"LangChainCohere\"\n",
        ")\n",
        "\n",
        "def display_quiz(state: StateDocument) -> StateDocument:\n",
        "    \"\"\"\n",
        "    Conducts a quiz by asking questions to the user and scoring their answers.\n",
        "\n",
        "    Args:\n",
        "        state (STATE): The current state containing questions, scores, and progress.\n",
        "\n",
        "    Returns:\n",
        "        STATE: The updated state after the quiz has been completed.\n",
        "    \"\"\"\n",
        "    state['current_question'] = 0\n",
        "    # Loop through all questions\n",
        "    while state['current_question'] < state['total_questions']:\n",
        "        # Get the current question data\n",
        "        question_data = state['questions'][state['current_question']]\n",
        "        question_text = question_data[\"question\"]\n",
        "        options = question_data[\"options\"]  # Get options for the current question\n",
        "\n",
        "        # Present the question and options to the user\n",
        "        print(f\"\\n\\nQuestion {state['current_question'] + 1}: {question_text}\\n\")\n",
        "        for option in options:\n",
        "            print(option)\n",
        "        # Instruct the user on how to answer\n",
        "        display(Markdown(\"\\nPlease answer with A, B, C, or D.\"))\n",
        "\n",
        "        # Get and validate user input\n",
        "        while True:\n",
        "            user_answer = __builtins__.input(\"Your answer: \").strip().lower()  # Get user input and strip whitespace\n",
        "            if user_answer in ['a', 'b', 'c', 'd']:\n",
        "                break  # Valid answer; exit the loop\n",
        "            else:\n",
        "               display(Markdown(\"\\nInvalid answer. Please answer with A, B, C, or D.\"))\n",
        "\n",
        "        # Check the answer and update score\n",
        "        if user_answer.upper() == question_data[\"answer\"]:  # Compare with the correct answer in uppercase\n",
        "            score = 1  # Award 1 point for a correct answer\n",
        "            # print(\"Correct!\\n\\n Explanation: \", question_data[\"explanation\"])\n",
        "            display(Markdown(\"Correct!\"))\n",
        "        else:\n",
        "            score = 0\n",
        "            # print(\"Incorrect. The correct answer was:\", question_data[\"answer\"], \"\\n\\n Explanation: \", question_data[\"explanation\"])\n",
        "            display(Markdown(f\"Incorrect. The correct answer was: {question_data['answer']}\"))\n",
        "\n",
        "\n",
        "        # Update the question's score and the overall total score\n",
        "        question_data[\"score\"] = score  # Store score in the question data\n",
        "        state['score'] += score  # Update total score\n",
        "        state['current_question'] += 1  # Move to the next question\n",
        "\n",
        "\n",
        "    display(Markdown(f\"Quiz finished! Your total score is: {state['score']}/{state['total_questions']}\"))\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "state: StateDocument = {\"human_input\": \"\", \"human_input_2\": \"\", \"decision\": \"\", \"chat\": \"\", \"ai_output\": \"\", \"score\": 0,\"reason\":\"\"}\n",
        "\n",
        "if collection_name:\n",
        "\n",
        "    vector_db = VectorDatabase(Chroma(collection_name=collection_name, embedding_function=embedding_function))\n",
        "\n"
      ],
      "metadata": {
        "id": "jGFjzt1ap8uE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(StateDocument)\n",
        "\n",
        "def quiz1(state:StateDocument):\n",
        "  questions(state)\n",
        "  node_2(vector_db, state)\n",
        "  display_quiz(state)\n",
        "  return state\n",
        "\n",
        "\n",
        "def chatbot(state: StateDocument):\n",
        "  while True:\n",
        "      state[\"human_input_2\"] = __builtins__.input(\"What do you want to know about? (type 'quit' to exit chat): \").strip()\n",
        "      if state[\"human_input_2\"].lower() == \"quit\":\n",
        "        print(\"Exiting chat mode.\")\n",
        "        break\n",
        "        # Pass config and across_thread_memory to node_3\n",
        "      node_3(vector_db, state, config, across_thread_memory)\n",
        "      display(Markdown(f\"Chat response: {state['chat']}\"))\n",
        "  return state\n",
        "\n",
        "\n",
        "workflow.add_node(\"quiz\",quiz1)\n",
        "workflow.add_node(\"chatbot\",chatbot)\n",
        "\n",
        "\n",
        "workflow.add_edge(START,\"chatbot\")\n",
        "workflow.add_edge(\"chatbot\",\"quiz\")\n",
        "workflow.add_edge(\"quiz\",END)\n",
        "\n",
        "\n",
        "graph = workflow.compile()\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "jr14-bzpSAs8",
        "outputId": "633d094a-9926-4b3a-a9f7-d07f2ec31bbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_user_input(state:StateDocument):\n",
        "   query_input = __builtins__.input(\"Type 'chat' to chat or 'quiz' to start the quiz: \").lower().strip()\n",
        "   state[\"decision\"] = query_input\n",
        "   return state\n",
        "\n",
        "def chatfile(state:StateDocument):\n",
        "    if state[\"decision\"] == \"chat\":\n",
        "        chatbot(vector_db, state)\n",
        "    return state\n",
        "\n",
        "\n",
        "def quiz(state:StateDocument):\n",
        "    if state[\"decision\"] == \"quiz\":\n",
        "        questions(state)\n",
        "        node_2(vector_db, state)\n",
        "        display_quiz(state)\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "def node_0(state: StateDocument) -> Literal[\"chat_file\",\"quiz\"]:\n",
        "\n",
        "    if state[\"decision\"] == \"chat\":\n",
        "        return \"chat_file\"\n",
        "    else:\n",
        "      return \"quiz\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "builder = StateGraph(StateDocument)\n",
        "builder.add_node(\"quiz\",quiz)\n",
        "builder.add_node(\"chat_file\",workflow.compile())\n",
        "\n",
        "\n",
        "builder.add_node(\"query\",get_user_input)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "builder.add_edge(START,\"query\")\n",
        "builder.add_conditional_edges(\"query\",node_0)\n",
        "builder.add_edge(\"quiz\",END)\n",
        "builder.add_edge(\"chat_file\",END)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "app = builder.compile()\n",
        "\n",
        "display(Image(app.get_graph(xray=1).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "k9ht_gHlqbbD",
        "outputId": "35600239-4d7f-4191-9daa-acdd69c89d91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = app.invoke(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "WXNuwdPiqdFm",
        "outputId": "6b0ec423-4ce4-4806-8723-7f95dd167826"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type 'chat' to chat or 'quiz' to start the quiz: chat\n",
            "What do you want to know about? (type 'quit' to exit chat): hi im muzzamil tell me about this file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Chat response: Hi Muzzamil!  This file appears to be a book excerpt about learning Python programming.  It covers topics such as setting up Python, handling errors (syntax and runtime), using variables, and includes exercises and challenges to help you learn by doing.  The book also offers bonus resources and online quizzes to aid your learning.  Is there anything specific you'd like to know about the file's contents?\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you want to know about? (type 'quit' to exit chat): quit\n",
            "Exiting chat mode.\n",
            "How many questions do you want to generate (0 to 25): 2\n",
            "\n",
            "\n",
            "Question 1: What is the result of the following Python code snippet? \n",
            "python\n",
            "string1 = \"abra\"\n",
            "string2 = \"cadabra\"\n",
            "magic_string = string1 + string2\n",
            "print(magic_string)\n",
            "\n",
            "\n",
            "A: abra cadabra\n",
            "B: abracadabra\n",
            "C: Error: Cannot concatenate strings\n",
            "D: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nPlease answer with A, B, C, or D."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your answer: s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nInvalid answer. Please answer with A, B, C, or D."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your answer: a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Incorrect. The correct answer was: B"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question 2: What will be printed to the console after executing this Python code? \n",
            "python\n",
            "my_string = \"Hello, World!\"\n",
            "print(my_string.upper().startswith(\"H\"))\n",
            "\n",
            "\n",
            "A: HELLO, WORLD!\n",
            "B: True\n",
            "C: False\n",
            "D: Error: 'str' object has no attribute 'startswith'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nPlease answer with A, B, C, or D."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your answer: b\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Incorrect. The correct answer was: C"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Quiz finished! Your total score is: 0/2"
          },
          "metadata": {}
        }
      ]
    }
  ]
}